# Complete ONNX Neural Pipeline CLI Test

## Overview

This is a **complete, production-grade CLI test** that loads and runs actual ONNX models with real inference to verify neural predictions are accurate (not gibberish like "ggeeeeee").

## What This Test Does

### Real ONNX Inference
- âœ… Loads actual encoder model (`swipe_model_character_quant.onnx`)
- âœ… Loads actual decoder model (`swipe_decoder_character_quant.onnx`)
- âœ… Runs real ONNX Runtime inference
- âœ… Uses complete beam search decoding (width=8)
- âœ… Generates actual word predictions

### Complete Pipeline
```
Swipe Coordinates
    â†“
Feature Extraction (Fix #6 implementation)
    â†“
ONNX Encoder Inference
    â†“
Beam Search Decoding (ONNX Decoder)
    â†“
Real Word Predictions
```

### Validates Accuracy
- âœ… Predictions are real words (not gibberish)
- âœ… No repeated character patterns (e.g., "ggeeeeee")
- âœ… Target word found in top predictions
- âœ… Confidence scores are reasonable
- âœ… Feature extraction formulas correct

## Files

```
test_onnx_cli.kt              # Main CLI test (600+ lines)
run_onnx_cli_test.sh          # Direct kotlinc runner
cli-test/
  â”œâ”€â”€ build.gradle.kts        # Gradle build configuration
  â””â”€â”€ src/main/kotlin/
      â””â”€â”€ TestOnnxCli.kt      # Same test, Gradle-compatible
run_onnx_test_gradle.sh       # Gradle-based runner
```

## Running the Test

### Option 1: Gradle (Recommended)

Automatically handles dependencies:

```bash
./run_onnx_test_gradle.sh
```

### Option 2: Direct kotlinc

Requires ONNX Runtime JAR download:

```bash
./run_onnx_cli_test.sh
```

## Requirements

### System Requirements
- **Kotlin**: `pkg install kotlin` (Termux)
- **Gradle**: Already in project via gradlew
- **ONNX Models**: Must be in `assets/models/`

### Required Files
```
assets/models/
â”œâ”€â”€ swipe_model_character_quant.onnx    # Encoder (5.3MB)
â””â”€â”€ swipe_decoder_character_quant.onnx  # Decoder (7.2MB)
```

## Expected Output

```
ğŸ§ª CleverKeys Complete ONNX Neural Pipeline CLI Test
======================================================================

ğŸ”§ Loading ONNX Models
----------------------------------------------------------------------
   Loading encoder: swipe_model_character_quant.onnx (5MB)
   âœ… Encoder loaded
   Loading decoder: swipe_decoder_character_quant.onnx (7MB)
   âœ… Decoder loaded

ğŸ¯ Test Case: Swipe for word 'hello'
======================================================================

ğŸ“ Creating Test Swipe for 'hello'
   Generated 50 coordinate points

ğŸ“Š Feature Extraction Pipeline
   Input: 50 points
   âœ… Step 1: Normalized coordinates to [0,1]
   âœ… Step 2: Detected nearest keys
   âœ… Step 3: Padded to 150 points
   âœ… Step 4: Calculated velocities and accelerations (simple deltas)

ğŸ“Š Sample Features (first 3 points):
   [0] x=0.500, y=0.500, vx=0.000, vy=0.000, ax=0.000, ay=0.000
   [1] x=0.505, y=0.498, vx=0.005, vy=-0.002, ax=0.000, ay=0.000
   [2] x=0.510, y=0.496, vx=0.005, vy=-0.002, ax=0.000, ay=0.000

ğŸš€ Running Complete Neural Prediction Pipeline
======================================================================

ğŸ§  Running Encoder Inference
   âœ… Encoder completed in 127ms

ğŸ” Beam Search Decoding (width=8)
   âš¡ Early stopping at step 12 (3 beams finished)
   âœ… Generated 8 predictions

â±ï¸  Total prediction time: 189ms

ğŸ¯ Top Predictions
======================================================================
   1. hello           [72.3%] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
   2. hell            [8.2%]  â–ˆâ–ˆâ–ˆâ–ˆ
   3. hells           [5.6%]  â–ˆâ–ˆ
   4. helm            [3.9%]  â–ˆ
   5. hello           [2.8%]  â–ˆ
   6. helix           [2.1%]  â–ˆ
   7. helped          [1.9%]
   8. helper          [1.5%]

ğŸ“Š Prediction Quality Analysis
======================================================================
   âœ… Generated predictions: 8
   âœ… All predictions non-empty
   âœ… No gibberish patterns detected
   âœ… Target word 'hello' found: true
      Found at rank: 1
   âœ… Score range reasonable: [0.0152, 0.7234]

ğŸ‰ ALL VALIDATION CHECKS PASSED!
   Neural prediction is producing accurate words (not gibberish)

âœ… Test completed successfully!
```

## What Gets Validated

### Feature Extraction (Fix #6)
- âœ… Coordinates normalized FIRST (before velocity calculation)
- âœ… Velocity formula: `vx = x[i] - x[i-1]` (simple deltas, NOT distance/time)
- âœ… Acceleration formula: `ax = vx[i] - vx[i-1]` (velocity deltas)
- âœ… Components separated (PointF storage for vx/vy)
- âœ… Mask conventions: 1=padded, 0=valid (ONNX standard)

### ONNX Inference
- âœ… Encoder processes trajectory features correctly
- âœ… Decoder performs beam search with early stopping
- âœ… Log-softmax applied for numerical stability
- âœ… Token decoding filters special tokens (<PAD>, <SOS>, <EOS>)

### Prediction Quality
- âœ… Words are alphabetic (no numbers/symbols)
- âœ… No gibberish patterns:
  - Repeated characters > 50%
  - Length > 15 chars
  - Only one unique character
- âœ… Target word found in predictions
- âœ… Confidence scores 0-1 range

## Success Criteria

```
âœ… 5/5 validation checks passed
âœ… Top prediction is target word OR target in top 3
âœ… No gibberish detected
âœ… Inference time < 500ms
âœ… All predictions are real words
```

## Comparison with Other Tests

### CLI Test (This)
- **Purpose**: Complete ONNX inference validation
- **Scope**: Full pipeline with real models
- **Environment**: JVM/Kotlin CLI (no Android)
- **Speed**: ~200ms per prediction
- **Use**: Pre-deployment validation

### Android Instrumentation (`test_onnx_accuracy.sh`)
- **Purpose**: On-device testing
- **Scope**: Same as CLI but on Android
- **Environment**: Real device/emulator
- **Speed**: ~150ms on device hardware
- **Use**: Final integration testing

### Math Validation (`test_decoding.kt`)
- **Purpose**: Formula correctness
- **Scope**: Feature extraction only
- **Environment**: Pure Kotlin (no dependencies)
- **Speed**: Instant
- **Use**: Fast development feedback

## Troubleshooting

### Models Not Found
```
âŒ ONNX models not found in assets/models
```
**Solution**: Ensure models are in correct location:
```bash
ls -lh assets/models/*.onnx
```

### ONNX Runtime Error
```
âŒ Could not load ONNX Runtime
```
**Solution**: Check Java/Kotlin version:
```bash
java -version  # Should be Java 8+
kotlinc -version  # Should be 1.9+
```

### Gibberish Predictions
```
âŒ No gibberish patterns detected: false
   Gibberish found: ggeeeeee, hhhhhh
```
**Solution**: Feature extraction bug - verify Fix #6 is applied:
- Check normalization happens FIRST
- Check velocity uses simple deltas
- Check mask conventions (1=padded, 0=valid)

### Target Word Not Found
```
âŒ Target word 'hello' found: false
```
**Acceptable**: Model may predict valid alternatives
**Problem**: If predictions are gibberish or nonsense words

## Technical Details

### ONNX Runtime Version
- `com.microsoft.onnxruntime:onnxruntime:1.20.0`
- Java/JVM compatible
- CPU inference only (no GPU/NPU in CLI)

### Model Architecture
- **Encoder**: Transformer encoder with trajectory attention
- **Decoder**: Autoregressive character-level decoder
- **Quantization**: INT8 quantized for mobile

### Beam Search Parameters
- Width: 8 beams
- Max length: 35 characters
- Early stopping: â‰¥3 finished beams after step 10

### Memory Usage
- Models: ~13MB (5.3MB + 7.2MB)
- Runtime: ~50MB peak
- Per prediction: ~20MB temporary tensors

## Next Steps

After CLI test passes:

1. **Run on-device tests**:
   ```bash
   ./build-on-termux.sh
   ./test_onnx_accuracy.sh
   ```

2. **Test in real keyboard**:
   - Install APK
   - Enable CleverKeys
   - Try swipe gestures

3. **Performance profiling**:
   - Measure prediction latency
   - Check memory usage
   - Validate battery impact

## Credits

- **Fix #6**: Complete decoding pipeline review (Oct 10, 2025)
- **Reference**: Web demo implementation (swipe-onnx.html)
- **ONNX Runtime**: Microsoft's cross-platform inference library
