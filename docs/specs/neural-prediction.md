# Neural Swipe Prediction System Specification

**Feature**: ONNX Transformer-Based Swipe-to-Text Prediction
**Status**: ğŸŸ¢ IMPLEMENTED (P0 bugs resolved, P1-P2 remaining)
**Priority**: P0 (Core functionality)
**Assignee**: N/A
**Date Created**: 2025-10-20
**Last Updated**: 2025-12-04

---

## TODOs

### âœ… RESOLVED - Critical Systems (P0)

All critical systems are fully implemented and verified as of 2025-12-04:

| Bug # | Issue | Resolution | Status |
|-------|-------|------------|--------|
| #257 | LanguageDetector missing | Implemented in `data/LanguageDetector.kt` (313 lines) | âœ… FIXED |
| #259 | NgramModel missing | Implemented in `NgramModel.kt` (350 lines) | âœ… FIXED |
| #262 | WordPredictor missing | Implemented in `WordPredictor.kt` (782 lines) | âœ… FIXED |
| #263 | UserAdaptationManager missing | Implemented in `data/UserAdaptationManager.kt` (291 lines) | âœ… FIXED |
| #273 | Training data lost on close | SQLite database implementation | âœ… FIXED |
| #274 | ML training system | External pipeline by design (ADR-003) | âœ… ARCHITECTURAL |
| #275 | Async prediction | Kotlin coroutines (ADR-004) | âœ… ARCHITECTURAL |
| #276 | Advanced gesture analysis | Neural network auto-learns features (ADR-005) | âœ… ARCHITECTURAL |

**Initialization Order Bug** (2025-11-14): Fixed race condition in CleverKeysService.kt where WordPredictor was initialized before its dependencies.

### âš ï¸ Outstanding Issues (P1-P2)

| Bug # | Issue | File | Impact | Est. Time |
|-------|-------|------|--------|-----------|
| #270 | Time delta calculation | SwipeMLData.kt | Training timestamps may be wrong | 1 hour |
| #271 | Consecutive duplicate filtering | SwipeMLData.kt | Noisy training data | 1 hour |
| #277 | Multi-language expansion | OptimizedVocabularyImpl.kt | Only English fully tested | 8-12 hours/language |

---

## 1. Feature Overview

### Purpose
Pure ONNX neural transformer architecture for converting swipe gestures into ranked word predictions. This is a **complete architectural replacement** of the original CGR (Continuous Gesture Recognition) system.

### Key Advantages Over Legacy CGR
- **Modern ML**: Transformer encoder-decoder vs. template matching
- **Automatic Learning**: Neural networks learn features from data
- **Better Accuracy**: Deep learning vs. statistical heuristics
- **Scalability**: Can improve with more training data
- **Simplicity**: 2000+ lines of Java CGR code replaced with ONNX inference

### Architecture Comparison

**Original (Java - CGR System)**:
```
Swipe â†’ Manual Feature Engineering (40+ features) â†’
Template Matching â†’ Dictionary Lookup â†’
Statistical Scoring â†’ Predictions
```

**Modern (Kotlin - ONNX System)**:
```
Swipe â†’ Feature Extraction (6 features) â†’
Transformer Encoder â†’ Beam Search Decoder â†’
Vocabulary Filter â†’ Predictions
```

### Current Status (Updated: 2025-11-14)
- **Core Pipeline**: âœ… COMPLETE (encoder + decoder + beam search)
- **Feature Extraction**: âœ… COMPLETE (smoothing, velocity, acceleration)
- **Tokenization**: âœ… COMPLETE (character-level)
- **WordPredictor System**: âœ… COMPLETE (dictionary, bigram, language detection, user adaptation)
- **Vocabulary**: âš ï¸ PARTIAL (English only, framework ready for multi-language)
- **Training Data**: âœ… COMPLETE (SQLite persistence - Bug #273 FIXED)
- **Multi-Language**: âš ï¸ FRAMEWORK READY (LanguageDetector implemented, assets needed)
- **User Adaptation**: âœ… COMPLETE (SharedPreferences-based learning)

---

## 2. Requirements

### Functional Requirements

**FR-1: Swipe Input Processing**
- âœ… Capture touch coordinates (x, y) and timestamps
- âœ… Smooth trajectory (moving average, window=3)
- âœ… Calculate velocity (first derivative)
- âœ… Calculate acceleration (second derivative)
- âœ… Normalize coordinates [0,1] (device-independent)
- âœ… Detect nearest keys (real positions or QWERTY grid)
- âœ… Pad/truncate to 150 points (fixed sequence length)

**FR-2: ONNX Encoder Inference**
- âœ… Input: trajectory_features [1, 150, 6], nearest_keys [1, 150]
- âœ… Model: swipe_model_character_quant.onnx (quantized)
- âœ… Output: memory tensor [1, 150, 256] (encoder representation)
- âœ… Transformer architecture with self-attention

**FR-3: Beam Search Decoder**
- âœ… Batched inference (50-70% speedup vs sequential)
- âœ… Beam width: 8 (configurable)
- âœ… Max length: 20 characters
- âœ… SOS/EOS token handling
- âœ… Score tracking (log probabilities)
- âœ… Early termination on EOS

**FR-4: Post-Processing**
- âœ… Token-to-character decoding
- âœ… Vocabulary filtering (dictionary lookup)
- âœ… Confidence score conversion (0-1000 scale)
- âœ… Ranking by score (descending)

**FR-5: Training Data Collection** (COMPLETE)
- âœ… Persistent storage via SQLite (Bug #273 - FIXED)
- âš ï¸ Time delta calculation needs verification (Bug #270)
- âš ï¸ Consecutive duplicates filtering needs verification (Bug #271)

**FR-6: Multi-Language Support** (FRAMEWORK READY)
- âœ… Language detection implemented (Bug #257 - FIXED)
- âš ï¸ Per-language models need assets (Bug #277)
- âš ï¸ User dictionaries framework ready, assets needed

**FR-7: User Adaptation** (COMPLETE)
- âœ… Personalization manager implemented (Bug #263 - FIXED)
- âœ… Frequency tracking via SharedPreferences
- âœ… User-specific corrections supported

### Non-Functional Requirements

**NFR-1: Performance**
- âœ… Encoder inference: < 30ms (achieved with quantization)
- âœ… Decoder inference: < 50ms (batched beam search)
- âœ… Total latency: < 100ms (end-to-end)
- âœ… Memory pooling (OptimizedTensorPool)
- âœ… GPU batching (BatchedMemoryOptimizer)

**NFR-2: Accuracy**
- âš ï¸ Top-1 accuracy: 65-75% (can improve with more training data)
- âš ï¸ Top-3 accuracy: 85-90% (needs vocabulary improvement)
- âš ï¸ Multi-language: Framework ready, needs asset files

**NFR-3: Resource Usage**
- âœ… Model size: ~8MB (quantized from ~30MB)
- âœ… Memory pooling prevents leaks
- âœ… Training data persisted to SQLite (Bug #273 FIXED)

---

## 3. Technical Design

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERACTION                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SwipeDetector.kt (Touch Events)               â”‚
â”‚  - ACTION_DOWN: Start gesture                             â”‚
â”‚  - ACTION_MOVE: Collect points                            â”‚
â”‚  - ACTION_UP: Trigger prediction                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SwipeInput.kt (Data Encapsulation)                 â”‚
â”‚  data class SwipeInput(                                    â”‚
â”‚    coordinates: List<PointF>,                              â”‚
â”‚    timestamps: List<Long>,                                 â”‚
â”‚    touchedKeys: List<Key>                                  â”‚
â”‚  )                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      OnnxSwipePredictorImpl.kt (Core Pipeline)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ SwipeTrajectoryProcessor (Feature Extraction)   â”‚      â”‚
â”‚  â”‚  - smoothTrajectory()                           â”‚      â”‚
â”‚  â”‚  - calculateVelocities()                        â”‚      â”‚
â”‚  â”‚  - calculateAccelerations()                     â”‚      â”‚
â”‚  â”‚  - normalizeCoordinates()                       â”‚      â”‚
â”‚  â”‚  - detectNearestKeys()                          â”‚      â”‚
â”‚  â”‚  - padOrTruncate(150 points)                    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                         â”‚                                  â”‚
â”‚                         â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ runEncoder() (Transformer Inference)            â”‚      â”‚
â”‚  â”‚  - Create input tensors [1,150,6], [1,150]     â”‚      â”‚
â”‚  â”‚  - Run ONNX encoder model                       â”‚      â”‚
â”‚  â”‚  - Output: memory [1,150,256]                   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                         â”‚                                  â”‚
â”‚                         â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ runBeamSearch() (Character Decoding)            â”‚      â”‚
â”‚  â”‚  - Initialize beams with SOS token              â”‚      â”‚
â”‚  â”‚  - BATCHED decoder inference (beam_width=8)     â”‚      â”‚
â”‚  â”‚  - Expand hypotheses, track scores              â”‚      â”‚
â”‚  â”‚  - Terminate on EOS or max_length               â”‚      â”‚
â”‚  â”‚  - Return top N candidates                      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                         â”‚                                  â”‚
â”‚                         â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ SwipeTokenizer (Token â†” Character)              â”‚      â”‚
â”‚  â”‚  - decode([2,5,8,12,3]) â†’ "hello"              â”‚      â”‚
â”‚  â”‚  - Special tokens: SOS=2, EOS=3, PAD=0, UNK=1   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    OptimizedVocabularyImpl.kt (Dictionary Filter)         â”‚
â”‚  - Check words against dictionary (English only)          â”‚
â”‚  - Filter OOV (out-of-vocabulary) predictions             â”‚
â”‚  - Bug #277: Multi-language support missing               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PredictionResult.kt (Output Format)                â”‚
â”‚  data class PredictionResult(                              â”‚
â”‚    words: List<String>,        // ["hello", "hallo"]      â”‚
â”‚    scores: List<Int>,          // [950, 850]              â”‚
â”‚    confidences: List<Float>    // [0.95, 0.85]            â”‚
â”‚  )                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            SuggestionBar.kt (UI Display)                   â”‚
â”‚  - Show top 3 predictions                                 â”‚
â”‚  - Highlight by confidence color                          â”‚
â”‚  - Handle user selection                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Critical Data Flows

**1. Feature Extraction Pipeline**:
```kotlin
// Input: SwipeInput
val rawCoords = swipeInput.coordinates          // [(100,250), (102,251), ...]
val timestamps = swipeInput.timestamps          // [1728567890123, 1728567890140, ...]

// Step 1: Smoothing (moving average, window=3)
val smoothed = smoothTrajectory(rawCoords)      // Reduce noise

// Step 2: Velocity (first derivative)
val velocities = calculateVelocities(smoothed, timestamps)
// Formula: velocity = distance / time_delta (pixels/sec)

// Step 3: Acceleration (second derivative)
val accelerations = calculateAccelerations(velocities, timestamps)
// Formula: accel = velocity_delta / time_delta (pixels/secÂ²)

// Step 4: Normalization [0,1]
val normalized = normalizeCoordinates(smoothed)
// normalized_x = x / keyboardWidth, normalized_y = y / keyboardHeight

// Step 5: Nearest key detection
val nearestKeys = detectNearestKeys(normalized)
// Returns character indices: a=4, b=5, ..., z=29

// Step 6: Padding to 150 points
val (features, keys, mask) = padOrTruncate(
    normalized, velocities, accelerations, nearestKeys, 150
)

// Output tensors:
// trajectory_features: [1, 150, 6] (x, y, vx, vy, ax, ay)
// nearest_keys: [1, 150] (character indices)
// src_mask: [1, 150] (attention mask - 1=real, 0=padding)
```

**2. Beam Search Algorithm**:
```kotlin
// Initialize beams with SOS token
var beams = listOf(Beam(tokens=[SOS], score=0.0))

for (step in 0 until max_length) {
    // BATCHED inference: all beams in single model call
    val batchSize = beams.size
    val inputIds = beams.map { it.tokens }.toBatchTensor()  // [batch, seq_len]

    // Run decoder model
    val logits = runDecoder(memory, inputIds)  // [batch, vocab_size]

    // Expand each beam
    val newBeams = mutableListOf<Beam>()
    for ((beamIdx, beam) in beams.withIndex()) {
        val topK = logits[beamIdx].topK(beam_width)  // Get top K tokens

        for ((tokenIdx, logProb) in topK) {
            if (tokenIdx == EOS) {
                finishedBeams.add(beam.copy(score = beam.score + logProb))
            } else {
                newBeams.add(Beam(
                    tokens = beam.tokens + tokenIdx,
                    score = beam.score + logProb
                ))
            }
        }
    }

    // Keep top beam_width beams by score
    beams = newBeams.sortedByDescending { it.score }.take(beam_width)

    // Early termination if all beams finished
    if (beams.isEmpty()) break
}

// Return best finished beams
return finishedBeams.sortedByDescending { it.score }
```

**3. Token-to-Character Decoding**:
```kotlin
// Token indices â†’ Characters
val CHAR_MAP = mapOf(
    4 to 'a', 5 to 'b', 6 to 'c', ..., 29 to 'z',
    30 to ' ', 31 to '\'', 32 to '-'
)

fun decode(tokens: List<Int>): String {
    return tokens
        .filter { it !in listOf(SOS, EOS, PAD, UNK) }
        .mapNotNull { CHAR_MAP[it] }
        .joinToString("")
}

// Example:
// tokens: [2, 8, 5, 12, 12, 15, 3]  (SOS, h, e, l, l, o, EOS)
// decoded: "hello"
```

### Model Architecture

**Encoder Model** (`swipe_model_character_quant.onnx`):
- **Type**: Transformer encoder
- **Input 1**: `trajectory_features` [batch, 150, 6]
  - Features: (x, y, velocity_x, velocity_y, accel_x, accel_y)
- **Input 2**: `nearest_keys` [batch, 150]
  - Character indices detected under each point
- **Input 3**: `src_mask` [batch, 150]
  - Attention mask (1=real point, 0=padding)
- **Output**: `memory` [batch, 150, 256]
  - Encoded representation of swipe trajectory
- **Size**: ~4MB (quantized INT8)
- **Layers**: 6 transformer encoder layers
- **Attention**: Multi-head self-attention (8 heads)

**Decoder Model** (`swipe_decoder_character_quant.onnx`):
- **Type**: Transformer decoder (character-level)
- **Input 1**: `memory` [batch, 150, 256] (from encoder)
- **Input 2**: `tgt_input_ids` [batch, seq_len] (partial sequence)
- **Output**: `logits` [batch, seq_len, vocab_size=35]
  - Next character probabilities
- **Size**: ~4MB (quantized INT8)
- **Vocabulary**: 35 tokens (SOS, EOS, PAD, UNK, a-z, space, ', -)
- **Max Length**: 20 characters

---

## 4. Implementation Plan

### Phase 1: Critical Bug Fixes (2-3 days)
**Priority: P0 - Fix data loss and training bugs**

1. **Bug #273: Persistent Training Data**
   - Create SQLite database schema
   - Migrate SwipeMLDataStore to use Room/SQLite
   - Implement batch insert for performance
   - Add data export/import functionality
   - Time: 4-6 hours

2. **Bug #270: Time Delta Calculation**
   - Fix addRawPoint() timestamp logic
   - Use proper millisecond differences
   - Time: 1 hour

3. **Bug #271: Consecutive Duplicate Filtering**
   - Add logic to skip duplicate keys in sequence
   - Preserve only direction changes
   - Time: 1 hour

### Phase 2: Multi-Language Support (1-2 weeks)
**Priority: P1 - Enable multiple languages**

1. **Bug #277: Multi-Language Infrastructure**
   - Add language detection (Bug #257 - 313 lines to port)
   - Per-language ONNX models
   - Per-language vocabularies
   - User dictionary support
   - Language switcher UI
   - Time: 8-12 hours implementation + model training

### Phase 3: User Adaptation (2-3 weeks)
**Priority: P1 - Personalization**

1. **Bug #263: UserAdaptationManager**
   - Port UserAdaptationManager.java (291 lines)
   - Frequency tracking
   - User-specific corrections
   - Personalized scoring adjustments
   - Time: 12-16 hours

### Phase 4: Training Infrastructure (4-6 weeks - External)
**Priority: P0 - Enable model improvements**

1. **Bug #274: ML Training System (External)**
   - Python/PyTorch training pipeline
   - Data preprocessing scripts
   - Model architecture definition
   - Training loop with validation
   - ONNX export scripts
   - Time: 2-3 weeks (full infrastructure)
   - Note: This is INTENTIONAL external training (ADR-003)

---

## 5. Testing Strategy

### Unit Tests

**Feature Extraction Tests**:
```kotlin
@Test
fun `smoothTrajectory reduces noise`() {
    val noisy = listOf(
        PointF(100f, 100f),
        PointF(105f, 102f),  // Noise spike
        PointF(102f, 101f)
    )
    val smoothed = smoothTrajectory(noisy)
    assertTrue(smoothed[1].x < noisy[1].x)  // Spike reduced
}

@Test
fun `velocity calculation is correct`() {
    val coords = listOf(PointF(0f, 0f), PointF(100f, 0f))
    val timestamps = listOf(0L, 1000L)  // 1 second apart
    val velocities = calculateVelocities(coords, timestamps)
    assertEquals(100f, velocities[0], 0.1f)  // 100 pixels/sec
}

@Test
fun `padding extends to 150 points`() {
    val coords = List(50) { PointF(it.toFloat(), 0f) }
    val (features, _, mask) = padOrTruncate(coords, ..., 150)
    assertEquals(150, features.size)
    assertEquals(50, mask.count { it == 1 })  // 50 real, 100 padded
}
```

**Beam Search Tests**:
```kotlin
@Test
fun `beam search returns top N candidates`() {
    val memory = createMockMemory()
    val beams = runBeamSearch(memory, beamWidth=8, maxLength=10)
    assertTrue(beams.size <= 8)
    assertTrue(beams[0].score >= beams[1].score)  // Sorted by score
}

@Test
fun `beam search terminates on EOS`() {
    val memory = createMockMemory()
    val beams = runBeamSearch(memory, beamWidth=1, maxLength=20)
    assertTrue(beams[0].tokens.last() == EOS || beams[0].tokens.size == 20)
}
```

**Tokenization Tests**:
```kotlin
@Test
fun `decode converts tokens to string`() {
    val tokens = listOf(SOS, 8, 5, 12, 12, 15, EOS)  // "hello"
    val decoded = SwipeTokenizer.decode(tokens)
    assertEquals("hello", decoded)
}

@Test
fun `decode filters special tokens`() {
    val tokens = listOf(SOS, PAD, 8, UNK, EOS)
    val decoded = SwipeTokenizer.decode(tokens)
    assertEquals("h", decoded)  // Only 'h' remains
}
```

### Integration Tests

**End-to-End Pipeline**:
```kotlin
@Test
fun `full pipeline produces predictions`() {
    val swipeInput = SwipeInput(
        coordinates = createMockSwipe(),  // Simulate "hello" swipe
        timestamps = createMockTimestamps(),
        touchedKeys = emptyList()
    )

    val predictions = onnxPredictor.predict(swipeInput)

    assertTrue(predictions.words.isNotEmpty())
    assertTrue(predictions.words[0] in listOf("hello", "hallo", "hell"))
    assertTrue(predictions.scores[0] > predictions.scores[1])
}
```

### Manual Testing Checklist

- [ ] Swipe "hello" â†’ predicts "hello" in top 3
- [ ] Swipe with noise â†’ smoothing reduces jitter
- [ ] Very short swipe (< 10 points) â†’ pads correctly
- [ ] Very long swipe (> 200 points) â†’ truncates to 150
- [ ] Fast swipe â†’ velocity/acceleration calculated
- [ ] Slow swipe â†’ low velocity values
- [ ] Multi-language model (if implemented) â†’ correct language detected
- [ ] User dictionary (if implemented) â†’ custom words appear

---

## 6. Success Criteria

### Functional Success
- âœ… Encoder inference < 30ms
- âœ… Decoder inference < 50ms (batched)
- âœ… Total latency < 100ms
- âœ… Training data persists across sessions (Bug #273 FIXED - SQLite)
- âš ï¸ Multi-language support (Bug #277 - framework ready, assets needed)
- âœ… User adaptation (Bug #263 FIXED)

### Technical Success
- âœ… ONNX models load and run
- âœ… Beam search produces ranked candidates
- âœ… Vocabulary filtering works
- âœ… Memory pooling prevents leaks
- âš ï¸ Top-3 accuracy â‰¥ 85% (can improve with more training data)

### User Experience Success
- âœ… Predictions appear quickly (< 100ms)
- âš ï¸ Top prediction usually correct (65-75% currently)
- âœ… Learns from user corrections (UserAdaptationManager implemented)
- âš ï¸ Multi-language switching (framework ready, needs assets)

---

## 7. References

### Documentation
- **Technical Reference**: `docs/ONNX_DECODE_PIPELINE.md` (28,319 bytes)
- **Architectural Decisions**: `docs/specs/architectural-decisions.md` (ADR-001 to ADR-006)
- **Review Status**: `docs/COMPLETE_REVIEW_STATUS.md` (Files 41-50, 57-100)

### Source Files
- **Core Pipeline**: `OnnxSwipePredictorImpl.kt` (~1500 lines)
- **Feature Extraction**: SwipeTrajectoryProcessor (embedded)
- **Beam Search**: runBeamSearch() method
- **Tokenization**: SwipeTokenizer (embedded)
- **Vocabulary**: `OptimizedVocabularyImpl.kt`
- **Training Data**: `SwipeMLData.kt`, `SwipeMLDataStore.kt`

### Models
- **Encoder**: `assets/models/swipe_model_character_quant.onnx` (~4MB)
- **Decoder**: `assets/models/swipe_decoder_character_quant.onnx` (~4MB)
- **Vocabulary**: `assets/models/vocabulary.txt` (English words)

### Bug Reports

| Bug # | Description | Status |
|-------|-------------|--------|
| #257 | LanguageDetector missing | âœ… FIXED |
| #259 | NgramModel missing | âœ… FIXED |
| #262 | WordPredictor integration | âœ… ARCHITECTURAL (works alongside ONNX) |
| #263 | UserAdaptationManager missing | âœ… FIXED |
| #270 | Time delta calculation | âš ï¸ Needs verification |
| #271 | Consecutive duplicates filter | âš ï¸ Needs verification |
| #273 | Training data persistence | âœ… FIXED (SQLite) |
| #274 | ML training external | âœ… ARCHITECTURAL (by design) |
| #275 | Async prediction | âœ… ARCHITECTURAL (coroutines) |
| #276 | Trace analyzer | âœ… ARCHITECTURAL (neural features) |
| #277 | Multi-language expansion | âš ï¸ Framework ready, needs assets |

---

## 8. Notes

### Why ONNX Over CGR
- **ADR-001**: Pure ONNX neural prediction (intentional replacement)
- **ADR-002**: Template generation â†’ neural training
- **ADR-003**: External ML training (Python/PyTorch)
- **ADR-004**: Coroutines over HandlerThread
- **ADR-005**: Neural feature learning (40+ features â†’ 6 features)

### Implementation Complexity
- **Core Pipeline**: âœ… COMPLETE (high complexity, well-implemented)
- **Data Persistence**: âœ… COMPLETE (SQLite implementation)
- **Multi-Language**: âš ï¸ FRAMEWORK READY (needs asset files for each language)
- **User Adaptation**: âœ… COMPLETE (SharedPreferences-based learning)

### Future Enhancements
1. On-device fine-tuning (federated learning)
2. Multilingual single model (instead of per-language)
3. Subword tokenization (BPE) for better vocabulary coverage
4. Contextual predictions (previous words)
5. Emoji/symbol prediction
6. Voice-to-swipe hybrid input

---

**Last Updated**: 2025-12-04
**Status**: âœ… Core complete, all P0 bugs resolved
**Priority**: P1-P2 remaining (time delta calculation, duplicate filtering, multi-language expansion)
