<!DOCTYPE html>
<html lang="en" class="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Prediction - CleverKeys Documentation</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            darkMode: 'class',
            theme: {
                extend: {
                    colors: {
                        'ck-purple': '#9b59b6',
                        'ck-purple-dark': '#6b21a8',
                        'ck-purple-light': '#c39bd3',
                        'ck-dark': '#0f0f1a',
                        'ck-surface': '#1a1a2e',
                        'ck-card': '#242438',
                    }
                }
            }
        }
    </script>
    <style>
        .gradient-text {
            background: linear-gradient(135deg, #9b59b6 0%, #c39bd3 50%, #9b59b6 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
    </style>
</head>
<body class="bg-ck-dark text-gray-100 min-h-screen">
    <!-- Nav -->
    <nav class="sticky top-0 bg-ck-dark/95 backdrop-blur border-b border-gray-800 z-50">
        <div class="container mx-auto px-6 py-4 flex justify-between items-center">
            <a href="../" class="flex items-center gap-3">
                <img src="https://raw.githubusercontent.com/tribixbite/CleverKeys/main/res/mipmap-xxxhdpi/ic_launcher.png" alt="CleverKeys" class="w-8 h-8 rounded-lg">
                <span class="font-bold">CleverKeys</span>
            </a>
            <div class="flex gap-4">
                <a href="./" class="text-gray-400 hover:text-white transition-colors">All Specs</a>
                <a href="../" class="text-gray-400 hover:text-white transition-colors">Home</a>
            </div>
        </div>
    </nav>

    <!-- Breadcrumb -->
    <div class="container mx-auto px-6 py-4 pt-20">
        <div class="flex items-center gap-2 text-sm text-gray-500">
            <a href="../" class="hover:text-ck-purple">Home</a>
            <span>/</span>
            <a href="./" class="hover:text-ck-purple">Specs</a>
            <span>/</span>
            <span class="text-gray-300">Neural Prediction</span>
        </div>
    </div>

    <!-- Header -->
    <header class="container mx-auto px-6 pb-8">
        <div class="flex items-center gap-3 mb-4">
            <span class="px-3 py-1 text-sm rounded-full" style="background: #9b59b620; color: #9b59b6">Core</span>
            <span class="px-3 py-1 text-sm rounded-full bg-ck-card text-gray-400">v1.0.0</span>
        </div>
        <h1 class="text-4xl font-bold gradient-text mb-2">Neural Prediction</h1>
        <p class="text-xl text-gray-400">ONNX transformer-based swipe typing engine</p>
    </header>

    <!-- Content -->
    <main class="container mx-auto px-6 pb-20">
        <div class="bg-ck-surface rounded-2xl p-8 max-w-4xl">
            <h1 class="text-3xl font-bold mb-6 gradient-text">Neural Swipe Prediction System</h1>

<h2 class="text-2xl font-bold mt-8 mb-4 text-ck-purple">Overview</h2>

<p class="mb-4 text-gray-300">Pure ONNX neural transformer architecture for converting swipe gestures into ranked word predictions. This replaces legacy template-matching (CGR) with deep learning inference: trajectory → encoder → beam search decoder → vocabulary filter → predictions.</p>

<h2 class="text-2xl font-bold mt-8 mb-4 text-ck-purple">Key Files</h2>

<table class="w-full mb-4 border-collapse"><thead class="border-b border-gray-700"><tr><th class="px-4 py-2 text-left font-semibold text-ck-purple-light">File</th><th class="px-4 py-2 text-left font-semibold text-ck-purple-light">Class/Function</th><th class="px-4 py-2 text-left font-semibold text-ck-purple-light">Purpose</th></tr></thead><tbody><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">src/main/kotlin/tribixbite/cleverkeys/OnnxSwipePredictorImpl.kt</code></td><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">OnnxSwipePredictorImpl</code></td><td class="px-4 py-2 text-gray-300">Core prediction pipeline (~1500 lines)</td></tr><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">src/main/kotlin/tribixbite/cleverkeys/SwipeTrajectoryProcessor.kt</code></td><td class="px-4 py-2 text-gray-300">Feature extraction</td><td class="px-4 py-2 text-gray-300">Smoothing, velocity, normalization</td></tr><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">src/main/kotlin/tribixbite/cleverkeys/OptimizedVocabularyImpl.kt</code></td><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">OptimizedVocabulary</code></td><td class="px-4 py-2 text-gray-300">Dictionary filtering</td></tr><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">src/main/kotlin/tribixbite/cleverkeys/data/LanguageDetector.kt</code></td><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">LanguageDetector</code></td><td class="px-4 py-2 text-gray-300">Multi-language detection</td></tr><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">assets/models/swipe_model_character_quant.onnx</code></td><td class="px-4 py-2 text-gray-300">Encoder model</td><td class="px-4 py-2 text-gray-300">~4MB quantized</td></tr><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">assets/models/swipe_decoder_character_quant.onnx</code></td><td class="px-4 py-2 text-gray-300">Decoder model</td><td class="px-4 py-2 text-gray-300">~4MB quantized</td></tr></tbody></table>
<h2 class="text-2xl font-bold mt-8 mb-4 text-ck-purple">Architecture</h2>

<pre class="bg-ck-dark p-4 rounded-lg overflow-x-auto"><code class="language-text">┌─────────────────────────────────────────────────────────────┐
│                    SwipeInput (Touch Events)                 │
│  coordinates: List&lt;PointF&gt;, timestamps: List&lt;Long&gt;          │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│           SwipeTrajectoryProcessor (Feature Extraction)      │
│  - smoothTrajectory() (moving average, window=3)            │
│  - calculateVelocities() (first derivative)                 │
│  - calculateAccelerations() (second derivative)             │
│  - normalizeCoordinates() [0,1]                             │
│  - detectNearestKeys() (character indices)                  │
│  - padOrTruncate(150 points)                                │
│                                                              │
│  Output: trajectory_features [1, 150, 6]                    │
│          nearest_keys [1, 150]                              │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│              runEncoder() (Transformer Inference)            │
│  Input:  trajectory_features [1, 150, 6]                    │
│          nearest_keys [1, 150]                              │
│          src_mask [1, 150]                                  │
│  Output: memory [1, 150, 256]                               │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│              runBeamSearch() (Character Decoding)            │
│  - Batched decoder inference (beam_width=8)                 │
│  - Expand hypotheses, track log-probabilities               │
│  - Terminate on EOS or max_length=20                        │
│  Output: List&lt;Beam(tokens, score)&gt;                          │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│              SwipeTokenizer (Token ↔ Character)              │
│  decode([2,8,5,12,12,15,3]) → "hello"                       │
│  Special tokens: SOS=2, EOS=3, PAD=0, UNK=1                 │
│  Vocabulary: a-z (4-29), space (30), ' (31), - (32)         │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│           OptimizedVocabulary (Dictionary Filter)            │
│  - Filter OOV predictions                                   │
│  - Rank by frequency + neural confidence                    │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                     PredictionResult                         │
│  words: List&lt;String&gt;, scores: List&lt;Int&gt;, confidences        │
└─────────────────────────────────────────────────────────────┘</code></pre>

<h2 class="text-2xl font-bold mt-8 mb-4 text-ck-purple">Configuration</h2>

<table class="w-full mb-4 border-collapse"><thead class="border-b border-gray-700"><tr><th class="px-4 py-2 text-left font-semibold text-ck-purple-light">Key</th><th class="px-4 py-2 text-left font-semibold text-ck-purple-light">Type</th><th class="px-4 py-2 text-left font-semibold text-ck-purple-light">Default</th><th class="px-4 py-2 text-left font-semibold text-ck-purple-light">Description</th></tr></thead><tbody><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">neural_beam_width</code></td><td class="px-4 py-2 text-gray-300">Int</td><td class="px-4 py-2 text-gray-300">6</td><td class="px-4 py-2 text-gray-300">Beam search width (more = better quality, slower)</td></tr><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">neural_max_length</code></td><td class="px-4 py-2 text-gray-300">Int</td><td class="px-4 py-2 text-gray-300">20</td><td class="px-4 py-2 text-gray-300">Maximum word length in characters</td></tr><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300"><code class="bg-ck-dark px-1 rounded">neural_confidence_threshold</code></td><td class="px-4 py-2 text-gray-300">Float</td><td class="px-4 py-2 text-gray-300">0.3</td><td class="px-4 py-2 text-gray-300">Minimum confidence to show prediction</td></tr></tbody></table>
<h2 class="text-2xl font-bold mt-8 mb-4 text-ck-purple">Implementation Details</h2>

<h3 class="text-xl font-semibold mt-6 mb-3 text-ck-purple-light">Feature Extraction Pipeline</h3>

<pre class="bg-ck-dark p-4 rounded-lg overflow-x-auto"><code class="language-kotlin">// Input: SwipeInput
val rawCoords = swipeInput.coordinates      // [(100,250), (102,251), ...]
val timestamps = swipeInput.timestamps      // [1728567890123, 1728567890140, ...]

// Step 1: Smoothing (moving average, window=3)
val smoothed = smoothTrajectory(rawCoords)

// Step 2: Velocity (first derivative)
val velocities = calculateVelocities(smoothed, timestamps)
// Formula: velocity = distance / time_delta (pixels/sec)

// Step 3: Acceleration (second derivative)
val accelerations = calculateAccelerations(velocities, timestamps)

// Step 4: Normalization [0,1]
val normalized = normalizeCoordinates(smoothed)
// normalized_x = x / keyboardWidth, normalized_y = y / keyboardHeight

// Step 5: Nearest key detection
val nearestKeys = detectNearestKeys(normalized)
// Returns character indices: a=4, b=5, ..., z=29

// Step 6: Padding to 150 points
val (features, keys, mask) = padOrTruncate(
    normalized, velocities, accelerations, nearestKeys, 150
)

// Output tensors:
// trajectory_features: [1, 150, 6] (x, y, vx, vy, ax, ay)
// nearest_keys: [1, 150] (character indices)
// src_mask: [1, 150] (attention mask - 1=real, 0=padding)</code></pre>

<h3 class="text-xl font-semibold mt-6 mb-3 text-ck-purple-light">Beam Search Algorithm</h3>

<pre class="bg-ck-dark p-4 rounded-lg overflow-x-auto"><code class="language-kotlin">// Initialize beams with SOS token
var beams = listOf(Beam(tokens=[SOS], score=0.0))

for (step in 0 until max_length) {
    // BATCHED inference: all beams in single model call
    val batchSize = beams.size
    val inputIds = beams.map { it.tokens }.toBatchTensor()  // [batch, seq_len]

    // Run decoder model
    val logits = runDecoder(memory, inputIds)  // [batch, vocab_size]

    // Expand each beam
    val newBeams = mutableListOf&lt;Beam&gt;()
    for ((beamIdx, beam) in beams.withIndex()) {
        val topK = logits[beamIdx].topK(beam_width)

        for ((tokenIdx, logProb) in topK) {
            if (tokenIdx == EOS) {
                finishedBeams.add(beam.copy(score = beam.score + logProb))
            } else {
                newBeams.add(Beam(
                    tokens = beam.tokens + tokenIdx,
                    score = beam.score + logProb
                ))
            }
        }
    }

    // Keep top beam_width beams by score
    beams = newBeams.sortedByDescending { it.score }.take(beam_width)

    if (beams.isEmpty()) break
}

return finishedBeams.sortedByDescending { it.score }</code></pre>

<h3 class="text-xl font-semibold mt-6 mb-3 text-ck-purple-light">Token Mapping</h3>

<pre class="bg-ck-dark p-4 rounded-lg overflow-x-auto"><code class="language-kotlin">val CHAR_MAP = mapOf(
    4 to 'a', 5 to 'b', 6 to 'c', 7 to 'd', 8 to 'e',
    9 to 'f', 10 to 'g', 11 to 'h', 12 to 'i', 13 to 'j',
    14 to 'k', 15 to 'l', 16 to 'm', 17 to 'n', 18 to 'o',
    19 to 'p', 20 to 'q', 21 to 'r', 22 to 's', 23 to 't',
    24 to 'u', 25 to 'v', 26 to 'w', 27 to 'x', 28 to 'y',
    29 to 'z', 30 to ' ', 31 to '\'', 32 to '-'
)

// Special tokens
const val PAD = 0
const val UNK = 1
const val SOS = 2
const val EOS = 3

fun decode(tokens: List&lt;Int&gt;): String {
    return tokens
        .filter { it !in listOf(SOS, EOS, PAD, UNK) }
        .mapNotNull { CHAR_MAP[it] }
        .joinToString("")
}

// Example:
// tokens: [2, 8, 5, 12, 12, 15, 3]  (SOS, h, e, l, l, o, EOS)
// decoded: "hello"</code></pre>

<h3 class="text-xl font-semibold mt-6 mb-3 text-ck-purple-light">Model Architecture</h3>

<p class="mb-4 text-gray-300"><strong>Encoder Model</strong> (<code class="bg-ck-dark px-1 rounded">swipe_model_character_quant.onnx</code>):</p>
<ul class="mb-4 space-y-1"><li class="ml-4">&#8226; Type: Transformer encoder (6 layers, 8 attention heads)</li>
<li class="ml-4">&#8226; Input 1: <code class="bg-ck-dark px-1 rounded">trajectory_features</code> [batch, 150, 6]</li>
<li class="ml-4">&#8226; Input 2: <code class="bg-ck-dark px-1 rounded">nearest_keys</code> [batch, 150]</li>
<li class="ml-4">&#8226; Input 3: <code class="bg-ck-dark px-1 rounded">src_mask</code> [batch, 150]</li>
<li class="ml-4">&#8226; Output: <code class="bg-ck-dark px-1 rounded">memory</code> [batch, 150, 256]</li>
<li class="ml-4">&#8226; Size: ~4MB (INT8 quantized)</li>
</ul>
<p class="mb-4 text-gray-300"><strong>Decoder Model</strong> (<code class="bg-ck-dark px-1 rounded">swipe_decoder_character_quant.onnx</code>):</p>
<ul class="mb-4 space-y-1"><li class="ml-4">&#8226; Type: Transformer decoder (character-level)</li>
<li class="ml-4">&#8226; Input 1: <code class="bg-ck-dark px-1 rounded">memory</code> [batch, 150, 256]</li>
<li class="ml-4">&#8226; Input 2: <code class="bg-ck-dark px-1 rounded">tgt_input_ids</code> [batch, seq_len]</li>
<li class="ml-4">&#8226; Output: <code class="bg-ck-dark px-1 rounded">logits</code> [batch, seq_len, 35]</li>
<li class="ml-4">&#8226; Vocabulary: 35 tokens (special + a-z + punctuation)</li>
<li class="ml-4">&#8226; Size: ~4MB (INT8 quantized)</li>
</ul>
<h3 class="text-xl font-semibold mt-6 mb-3 text-ck-purple-light">Performance Characteristics</h3>

<table class="w-full mb-4 border-collapse"><thead class="border-b border-gray-700"><tr><th class="px-4 py-2 text-left font-semibold text-ck-purple-light">Operation</th><th class="px-4 py-2 text-left font-semibold text-ck-purple-light">Target</th><th class="px-4 py-2 text-left font-semibold text-ck-purple-light">Method</th></tr></thead><tbody><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300">Encoder inference</td><td class="px-4 py-2 text-gray-300">< 30ms</td><td class="px-4 py-2 text-gray-300">INT8 quantization</td></tr><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300">Decoder inference</td><td class="px-4 py-2 text-gray-300">< 50ms</td><td class="px-4 py-2 text-gray-300">Batched beam search</td></tr><tr class="border-b border-gray-800"><td class="px-4 py-2 text-gray-300">Total latency</td><td class="px-4 py-2 text-gray-300">< 100ms</td><td class="px-4 py-2 text-gray-300">Memory pooling</td></tr></tbody></table>
<h3 class="text-xl font-semibold mt-6 mb-3 text-ck-purple-light">Memory Optimization</h3>

<pre class="bg-ck-dark p-4 rounded-lg overflow-x-auto"><code class="language-kotlin">// OptimizedTensorPool prevents allocation during inference
class OptimizedTensorPool {
    private val featureBuffer = FloatArray(150 * 6)
    private val keyBuffer = LongArray(150)
    private val maskBuffer = FloatArray(150)

    fun getFeatureTensor(): OnnxTensor {
        return OnnxTensor.createTensor(env, featureBuffer, shape)
    }
}</code></pre>

        </div>
    </main>

    <!-- Footer -->
    <footer class="container mx-auto px-6 py-8 text-center text-gray-500 text-sm border-t border-gray-800">
        <p>CleverKeys Documentation - Generated from specs</p>
    </footer>
</body>
</html>